# Глава 51. Инструментарий: от теории к практике

В прошлой главе мы договорились: тесты — это не "галочка", а способ жить спокойнее. Теперь давай про практику: что именно ставят на проекте и как сделать так, чтобы тесты не были отдельной болью.

Я предлагаю думать не "какой пакет скачать", а "какой вопрос мы хотим закрыть":

- быстро проверить логику и поведение компонентов;
- проверить интеграцию с API (и ошибки тоже);
- прогнать ключевой пользовательский сценарий "как в жизни";
- получить удобный цикл разработки: написал → запустил → понял, что сломалось.

---

## Быстрая обратная связь: Vitest/Jest и React Testing Library

Типовой стек для unit и integration тестов — это тандем раннера тестов и библиотеки для работы с компонентами. **Vitest** или **Jest** запускают код, а **React Testing Library** позволяет общаться с компонентами «на языке пользователя».

### Vitest vs Jest: выбираем без фанатизма

**Vitest** хорош, когда хочется современного DX: быстрый запуск и удобный watch, отлично дружит с Vite-экосистемой, "упал тест" обычно читается без расшифровки. Новый проект + Vite → чаще берут **Vitest**.

**Jest** хорош, когда проект уже живёт в Jest-мире: де-факто стандарт в огромном количестве репозиториев, много готовых примеров/интеграций, мигрировать "просто потому что Vitest моднее" редко стоит усилий. Старый проект/команда с привычками → чаще берут **Jest**.

Лучший раннер — тот, который **не мешает** и запускается за секунды.

### React Testing Library: язык пользователя

Testing Library ценят не за API, а за подход. Мы ищем элементы так, как их "видит" пользователь (текст, role, label), проверяем поведение и результат на экране, избегаем тестов вида "проверим, что вызвалась внутренняя функция".

Если тест читается как мини-история — он обычно живёт долго:

- «пользователь нажал кнопку»
- «увидел ошибку/успех»
- «форма отправилась/не отправилась»

И это сильно снижает шанс, что тест сломается при нормальном рефакторинге.

Мы не проверяем внутренности функции, мы проверяем, **появилась ли кнопка и сменился ли текст после клика**. Это делает тесты устойчивыми к рефакторингу кода.

```jsx
// Плохо: проверяем реализацию
expect(component.state.isOpen).toBe(true)

// Хорошо: проверяем поведение
expect(screen.getByText('Modal is open')).toBeInTheDocument()
```

Тест должен отвечать на вопрос: "видит ли пользователь то, что должен видеть?", а не "правильно ли работает внутренняя логика компонента?".

---

## Работа с окружением: моки и MSW

Моки нужны, чтобы сделать тест быстрым и детерминированным. Но "перемокать" — очень легко. Что обычно мокают (и это нормально): сеть (`fetch`, `axios`) — чтобы не зависеть от бэка, время (таймеры, `Date`) — чтобы сценарии не дрожали, тяжёлые внешние интеграции (карты, аналитика) — если они не цель теста.

Что лучше не мокать без причины: собственную бизнес-логику "просто чтобы было проще", важные куски поведения компонента (иначе вы не проверяете продукт).

Нормальная стратегия по уровням: **Unit** — мокаете всё вокруг, проверяете маленькую логику. **Integration** — мокаете только внешнее (API), а внутри приложения пусть всё работает по-настоящему.

Если вам постоянно приходится мокать половину приложения, это часто намёк: границы модулей/слоёв стоит сделать чище.

### MSW: мок API без ощущения фальши

Вместо имитации функций (моков) лучше имитировать целые сетевые ответы через MSW. MSW хорош тем, что вы не подменяете `fetch` руками. Вы задаёте "серверные ответы", а приложение делает запросы как обычно.

Почему это обычно ощущается лучше:

- тесты остаются похожими на реальную работу приложения;
- проще покрывать негативные сценарии (400/401/500);
- меньше "магии" и случайных моков в каждом тесте.

Если приложение активно общается с API, MSW обычно окупается очень быстро. Тесты становятся "честнее", потому что проверяют реальное поведение приложения, а не симуляцию симуляции.

---

## E2E на Playwright: минимум, который даёт максимум пользы

E2E — самый дорогой уровень. Поэтому цель не "покрыть всё", а защитить самые болезненные регрессы.

Обычно достаточно 3–7 сценариев:

- логин/выход (если есть);
- критичная форма (регистрация/оплата/создание заказа);
- главный happy-path продуктового сценария.

Playwright часто выбирают за практичность:

- хорошие ожидания и дебаг;
- артефакты (trace/скриншоты/видео) экономят часы;
- параллельный прогон помогает держать скорость.

### Visual Regression Testing: автоматизация проверки верстки

Одна из самых мощных возможностей Playwright — это **Visual Regression Testing** (скриншотные тесты). Это способ автоматизировать проверку того, что верстка «не поехала» после изменений CSS, что вручную проверить почти невозможно.

**Как это работает:**

Playwright делает скриншот страницы или компонента и сравнивает его с эталонным. Если есть различия, тест падает, показывая, что именно изменилось.

**Когда это полезно:**

- После изменений CSS — убедиться, что стили не сломали верстку.
- После обновления библиотек — проверить, что UI-компоненты выглядят правильно.
- При рефакторинге — убедиться, что визуально ничего не изменилось.

**Ограничения:**

- Скриншотные тесты хрупкие — они могут падать из-за различий в шрифтах, рендеринге, или даже из-за разницы в окружении.
- Они не заменяют функциональные тесты — они проверяют только визуальную часть.

Но для проверки верстки это незаменимый инструмент, который экономит часы ручной проверки.

---

## Запуск локально и в CI: сделать "ритуал", а не "танец с бубном"

Плохой знак — когда тесты запускают только "перед релизом, потому что страшно".
Хороший знак — когда у команды есть простой ритм.

Что помогает:

- локально — быстрый watch-режим для unit/integration;
- в CI — стабильный прогон и понятный вывод ошибок;
- E2E — отдельным джобом (или хотя бы перед релизом), чтобы не тормозить каждый PR.

Самое важное правило: **быстрее и стабильнее = тесты запускают чаще**.

### Как разбирать падения (и не ненавидеть тесты)

Когда тест упал, есть три причины:

- **сломался код** (это хорошо: тест вас спас);
- **сломался тест** (ожидание было неверным или тест хрупкий);
- **сломался окружение** (flaky/тайминги/нестабильность).

Мини-чек-лист, который реально помогает:

- что именно ожидалось и что получили?
- не используем ли мы таймауты вместо ожидания события?
- если это E2E — смотрим trace/видео: там обычно сразу видно "где жизнь пошла не так".

### Где хранить тесты: рядом с кодом или отдельно

Есть два рабочих подхода — выберите один и держитесь его.

1) **Рядом с кодом** (`Component.test.tsx` рядом с `Component.tsx`)
- удобно менять код и тест вместе;
- тесты редко "отрываются" и не превращаются в музей.

2) **Отдельная папка** (`__tests__/`)
- иногда удобно для больших модулей;
- но есть риск, что тесты перестанут обновлять синхронно с кодом.

Важнее не "правильность", а единообразие внутри репозитория.

### Минимальные команды, которые реально нужны

Не надо 20 скриптов. На большинстве проектов хватает:

- `test` — прогон unit/integration;
- `test:watch` — быстрый цикл разработки;
- `test:e2e` — E2E сценарии;
- `test:coverage` — иногда перед большим рефакторингом.

Если команда не понимает, какую команду запускать, тесты начинают игнорировать. Если понимает — тесты становятся привычкой.

---

## Мини-чек-лист "у нас нормальная тестовая система"

- Unit/integration прогоняются достаточно быстро, чтобы их запускали в работе.
- Нет flaky-тестов, которые "переезжают" перезапуском CI.
- E2E покрывают только критичные сценарии, а не всё подряд.
- Падение теста даёт понятный диагноз (что сломалось и где смотреть).

Если эти пункты выполнены — тесты перестают быть обязанностью и становятся поддержкой.

---

## Вопросы на собеседовании

### 1. В чём преимущество React Testing Library перед проверкой внутренней логики?

RTL заставляет писать тесты «языком пользователя» (поиск по тексту, ролям, label), что делает тесты устойчивыми к рефакторингу кода. Мы проверяем, появилась ли кнопка и сменился ли текст после клика, а не внутреннюю логику компонента. Тест должен отвечать на вопрос: "видит ли пользователь то, что должен видеть?", а не "правильно ли работает внутренняя логика компонента?".

### 2. Зачем использовать MSW вместо обычных моков `fetch`?

MSW перехватывает запросы на уровне сети, позволяя приложению работать «по-настоящему», что делает тесты более надёжными и упрощает проверку ошибок API. Вместо имитации функций (моков) мы имитируем целые сетевые ответы, что делает тесты "честнее" и ближе к реальной работе приложения. MSW особенно полезен для покрытия негативных сценариев (400/401/500).

### 3. Когда стоит выбирать Vitest вместо Jest?

Vitest лучше подходит для современных проектов на Vite благодаря скорости, удобному watch-режиму и совместимости с Vite-экосистемой. Jest остаётся стандартом для старых или крупных легаси-проектов, где миграция не оправдана. Лучший раннер — тот, который не мешает и запускается за секунды.

### 4. Что такое Visual Regression Testing и когда оно полезно?

Visual Regression Testing (скриншотные тесты) — это автоматизация проверки того, что верстка «не поехала» после изменений CSS. Playwright делает скриншот страницы и сравнивает его с эталонным. Это полезно после изменений CSS, обновления библиотек или при рефакторинге. Но скриншотные тесты хрупкие и не заменяют функциональные тесты — они проверяют только визуальную часть.

### 5. Как организовать запуск тестов в CI?

Unit/integration должны прогоняться быстро на каждый PR. E2E — отдельным джобом или перед релизом, чтобы не тормозить каждый PR. Если тесты становятся медленными — это сигнал улучшать стратегию, а не "терпеть". CI должен давать два ощущения: быстро (иначе никто не ждёт) и надёжно (иначе никто не верит).
